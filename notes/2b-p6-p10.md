# Computer Networks Problems - Solutions P6-P10

## Table of Contents
- [P6. HTTP/1.1 Specification (RFC 2616)](#p6-http11-specification-rfc-2616)
- [P7. Total Time Calculation with DNS Lookup](#p7-total-time-calculation-with-dns-lookup)
- [P8. Time for HTML with 8 Referenced Objects](#p8-time-for-html-with-8-referenced-objects)
- [P9. Institutional Network Response Time](#p9-institutional-network-response-time)
- [P10. Parallel vs Persistent HTTP on Short Link](#p10-parallel-vs-persistent-http-on-short-link)

---

## P6. HTTP/1.1 Specification (RFC 2616)

### a. Mechanism for signaling persistent connection closure

**Answer:**

**Mechanism:** The `Connection: close` header field is used to signal that the connection will be closed after the current request/response.

**Who can signal:**
- **Both client and server** can signal connection closure
- **Client:** Includes `Connection: close` in request to indicate it will close after receiving response
- **Server:** Includes `Connection: close` in response to indicate it will close after sending response

**Additional details:**
- In HTTP/1.1, persistent connections are the default
- Absence of `Connection: close` implies the connection should persist
- Either party can close the connection at any time, but using the header provides clean shutdown

### b. What encryption services are provided by HTTP?

**Answer:**

**HTTP itself provides NO encryption services.**

HTTP is a plaintext protocol that transmits data in clear text. For encryption, **HTTPS (HTTP Secure)** must be used, which combines:
- **HTTP** protocol
- **TLS/SSL (Transport Layer Security/Secure Sockets Layer)** for encryption

HTTPS provides:
- **Encryption** of data in transit
- **Authentication** of the server (and optionally client)
- **Integrity** protection against tampering

### c. Can a client open three or more simultaneous connections with a given server?

**Answer:** **YES**

**From RFC 2616, Section 8.1.4:**
- Clients that use persistent connections SHOULD limit the number of simultaneous connections
- **Recommendation:** Single-user clients should maintain at most 2 connections
- **However:** This is a SHOULD (recommendation), not a MUST (requirement)
- Browsers typically open 6-8 simultaneous connections to improve performance
- Servers may impose their own limits and refuse excessive connections

### d. Can one side start closing while the other is transmitting data?

**Answer:** **YES, this is possible**

**Explanation:**
- Either side may close an idle connection at any time
- Network delays and timing can cause race conditions:
  - Side A detects idle timeout and begins closing
  - Side B simultaneously sends a request (unaware of A's decision)
  - Side A receives request after initiating close sequence

**Result:**
- The transmitting side may receive a connection reset or error
- This is why RFC 2616 recommends clients be prepared to retry requests if a connection closes unexpectedly
- Idempotent methods (GET, HEAD, PUT, DELETE) can be safely retried
- Non-idempotent methods (POST) require user confirmation before retry

---

## P7. Total Time Calculation with DNS Lookup

**Given:**
- n DNS servers visited with RTTs: RTT₁, RTT₂, ..., RTTₙ
- RTT₀ = RTT between local host and web server
- Web page contains exactly one object (HTML text)
- Zero transmission time

**Solution:**

**Total Time = (RTT₁ + RTT₂ + ... + RTTₙ) + 2·RTT₀**

**Breakdown:**
1. **DNS Resolution:** RTT₁ + RTT₂ + ... + RTTₙ
    - Sequential queries to n DNS servers
    
2. **TCP Connection Setup:** RTT₀
    - 3-way handshake (SYN, SYN-ACK, ACK)
    - Takes 1 RTT
    
3. **HTTP Request/Response:** RTT₀
    - Client sends GET request
    - Server sends response
    - Takes 1 RTT

**Answer:** 
```
Total Time = Σ(RTTᵢ) + 2·RTT₀  where i = 1 to n
```

---

## P8. Time for HTML with 8 Referenced Objects

**Given:**
- HTML file references 8 very small objects on same server
- Neglect transmission times
- From P7: RTT₀ = RTT between client and server (after DNS resolution)

### a. Non-persistent HTTP with no parallel TCP connections

**Answer:** **18·RTT₀**

**Calculation:**
- Initial HTML file: 2·RTT₀ (1 for TCP setup + 1 for HTTP request/response)
- Each of 8 objects: 8 × 2·RTT₀ = 16·RTT₀
- **Total:** 2·RTT₀ + 16·RTT₀ = **18·RTT₀**

### b. Non-persistent HTTP with 6 parallel connections

**Answer:** **6·RTT₀**

**Calculation:**
- Initial HTML file: 2·RTT₀ (1 for TCP setup + 1 for HTTP)
- 8 objects in parallel (6 at a time):
  - First batch (6 objects): 2·RTT₀
  - Second batch (2 objects): 2·RTT₀
- **Total:** 2·RTT₀ + 2·RTT₀ + 2·RTT₀ = **6·RTT₀**

### c. Persistent HTTP

**Answer:** **3·RTT₀**

**Calculation:**
- TCP connection setup: 1·RTT₀
- Initial HTML file request/response: 1·RTT₀
- All 8 objects can be pipelined over same connection:
  - Without pipelining: 8·RTT₀
  - With pipelining: 1·RTT₀ (all requests sent at once, all responses return together)
- **Total (with pipelining):** 1·RTT₀ + 1·RTT₀ + 1·RTT₀ = **3·RTT₀**
- **Total (without pipelining):** 1·RTT₀ + 1·RTT₀ + 8·RTT₀ = **10·RTT₀**

**Best case with pipelining: 3·RTT₀**

---

## P9. Institutional Network Response Time

**Given:**
- Average object size: 1,000,000 bits
- Request rate: 16 requests/second
- Internet delay: 3 seconds (average)
- Access delay formula: Δ/(1 - Δβ)
  - Δ = average time to send object over access link
  - β = arrival rate of objects to access link

### a. Find total average response time

**Need to determine access link speed (assumed 15 Mbps based on typical problem):**

**Step 1: Calculate Δ**
```
Δ = Object size / Access link bandwidth
Δ = 1,000,000 bits / 15,000,000 bps
Δ = 0.0667 seconds
```

**Step 2: Calculate Δβ**
```
β = 16 requests/second
Δβ = 0.0667 × 16 = 1.067
```

**Problem:** Δβ > 1, which means the access delay formula gives a negative denominator → **system is unstable** (utilization > 100%)

**Let's assume access link is 100 Mbps (more realistic):**

```
Δ = 1,000,000 / 100,000,000 = 0.01 seconds
Δβ = 0.01 × 16 = 0.16

Access Delay = 0.01 / (1 - 0.16) = 0.01 / 0.84 = 0.0119 seconds

Total Response Time = Internet Delay + Access Delay
Total Response Time = 3 + 0.0119 ≈ 3.012 seconds
```

**Answer: ~3.01 seconds**

### b. Total response time with cache (miss rate = 0.4)

**With cache:**
- 40% of requests miss (go to Internet): 0.4 × 3.012 = 1.205 seconds
- 60% of requests hit (served from cache): 0.6 × ~0 ≈ 0 seconds
  - Cache hits have negligible delay (LAN speed)

**Total Response Time = 0.4 × 3.012 + 0.6 × 0.01**
**Total Response Time ≈ 1.21 seconds**

**Answer: ~1.21 seconds** (significant improvement!)

---

## P10. Parallel vs Persistent HTTP on Short Link

**Given:**
- Link: 10 meters, 150 bits/sec (both directions)
- Data packets: 100,000 bits
- Control packets: 200 bits
- N parallel connections each get 1/N bandwidth
- Each object: 100 Kbits
- Initial object contains 10 referenced objects

### Analysis:

**Link propagation delay:** 
```
d_prop = 10 m / (2 × 10⁸ m/s) ≈ 50 nanoseconds (negligible)
```

**Transmission times:**
```
Data packet: 100,000 bits / 150 bps = 666.67 seconds
Control packet: 200 bits / 150 bps = 1.33 seconds
```

### Non-persistent HTTP (sequential):
```
Per object: 
- TCP setup (SYN, SYN-ACK, ACK): 3 × 1.33 = 4 seconds
- HTTP request (control): 1.33 seconds
- HTTP response (data): 666.67 seconds
- Total per object: 672 seconds

Total for 11 objects: 11 × 672 = 7,392 seconds
```

### Non-persistent HTTP with N parallel connections:
```
Each connection gets 150/N bps

With N=10 parallel:
- Per object transmission: 100,000/(150/10) = 6,666.67 seconds
- All 10 referenced objects in parallel after initial: 
  - Initial object: 672 seconds
  - 10 objects in parallel: 6,666.67 seconds
  - Total: ~7,339 seconds
```

**Does parallel help?** **NO, barely!** The bandwidth is so limited that parallel connections make things worse due to overhead.

### Persistent HTTP:
```
- TCP setup once: 4 seconds
- Initial object: 1.33 + 666.67 = 668 seconds
- 10 objects sequentially: 10 × (1.33 + 666.67) = 6,680 seconds
- Total: 7,352 seconds
```

**Persistent savings over sequential non-persistent:**
```
Savings: 7,392 - 7,352 = 40 seconds (only TCP setup savings)
```

**Conclusion:**
- Parallel downloads **do NOT make sense** - extremely limited bandwidth makes overhead dominate
- Persistent HTTP provides **modest gains** (saves 10 TCP setups = 40 seconds)
- The bottleneck is the extremely slow 150 bps link
- Real benefit would come from increasing link bandwidth, not protocol optimizations