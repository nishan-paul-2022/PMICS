# Computer Networks Problems - Solutions P16-P20

## Table of Contents
- [P16. Message Body End Markers](#p16-message-body-end-markers)
- [P17. SMTP Spam Analysis](#p17-smtp-spam-analysis)
- [P18. DNS and Whois Investigation](#p18-dns-and-whois-investigation)
- [P19. DNS Hierarchy Exploration with dig](#p19-dns-hierarchy-exploration-with-dig)
- [P20. Determine Popular Web Servers from DNS Cache](#p20-determine-popular-web-servers-from-dns-cache)

---

## P16. Message Body End Markers

### SMTP - How it marks end of message body:

**Answer:** SMTP uses a line containing only a **single period (.)** to mark the end of message body.

**Format:**
```
DATA
354 Start mail input
[message headers]
[blank line]
[message body]
.
250 OK
```

**Transparency issue:**
- If message body contains a line with just a period, SMTP uses **byte-stuffing**
- Add an extra period at the beginning: `.` becomes `..`
- Receiver removes the extra period

### HTTP - How it marks end of message body:

**Answer:** HTTP uses **multiple methods:**

1. **Content-Length header:**
    ```
    Content-Length: 3874
    ```
    - Specifies exact number of bytes
    - Receiver reads exactly that many bytes

2. **Chunked Transfer Encoding:**
    ```
    Transfer-Encoding: chunked
    ```
    - Message sent in chunks
    - Each chunk has size followed by data
    - Zero-length chunk signals end

3. **Connection close:**
    - Server closes connection after sending body
    - End of body = end of connection

### Can HTTP use the same method as SMTP?

**Answer: NO, HTTP should NOT use SMTP's period-on-a-line method**

**Reasons:**

1. **Binary data:** HTTP frequently transfers binary data (images, videos, executables). A byte value of 0x2E0D0A (the period-newline sequence) could naturally occur in binary data, causing premature termination.

2. **Efficiency:** Content-Length is more efficient - receiver knows exactly how many bytes to read without scanning for special sequences.

3. **Byte-stuffing overhead:** Would require scanning and modifying binary content, adding overhead and complexity.

4. **Pipelining:** HTTP/1.1 supports pipelining multiple requests/responses. Content-Length allows immediate transition to next message without ambiguity.

5. **Partial content:** HTTP supports Range requests (partial content). Content-Length is essential for this feature.

**Conclusion:** SMTP's method works for text-based email content but is unsuitable for HTTP's diverse content types and performance requirements. Content-Length is the superior approach for HTTP.

---

## P17. SMTP Spam Analysis

**MTA Definition:** MTA stands for **Mail Transfer Agent** - a server that transfers email from one computer to another using SMTP.

### Given email headers:
```
From - Fri Nov 07 13:41:30 2008
Return-Path: <tennis5@pp33head.com>
Received: from barmail.cs.umass.edu (barmail.cs.umass.edu [128.119.240.3]) 
          by cs.umass.edu (8.13.1/8.12.6) for <hg@cs.umass.edu>; 
          Fri, 7 Nov 2008 13:27:10 -0500
Received: from asusus-4b96 (localhost [127.0.0.1]) 
          by barmail.cs.umass.edu (Spam Firewall) for <hg@cs.umass.edu>; 
          Fri, 7 Nov 2008 13:27:07 -0500 (EST)
Received: from asusus-4b96 ([58.88.21.177]) 
          by barmail.cs.umass.edu for <hg@cs.umass.edu>; 
          Fri, 07 Nov 2008 13:27:07 -0500 (EST)
Received: from [58.88.21.177] by inbnd55.exchangeddd.com; 
          Sat, 8 Nov 2008 01:27:07 +0700
From: "Jonny" <tennis5@pp33head.com>
To: <hg@cs.umass.edu>
Subject: How to secure your savings
```

### Analysis:

**Reading Received headers from BOTTOM to TOP** (they're added as mail travels):

1. **First hop:** `from [58.88.21.177] by inbnd55.exchangeddd.com`
    - Origin claims to be 58.88.21.177

2. **Second hop:** `from asusus-4b96 ([58.88.21.177]) by barmail.cs.umass.edu`
    - barmail.cs.umass.edu received from 58.88.21.177
    - The sending host claims to be "asusus-4b96"

3. **Third hop:** `from asusus-4b96 (localhost [127.0.0.1])`
    - Spam firewall processing (internal)

4. **Final hop:** `from barmail.cs.umass.edu by cs.umass.edu`
    - Legitimate internal relay

### Identifying the malicious host:

**Answer: The malicious host is at IP address 58.88.21.177 (claiming hostname asusus-4b96)**

**Evidence:**

1. **Suspicious hostname:** "asusus-4b96" is not a legitimate mail server name
2. **First external entry point:** 58.88.21.177 is where the mail entered the umass.edu system
3. **Forged From address:** tennis5@pp33head.com is likely fake
4. **Suspicious relay:** inbnd55.exchangeddd.com appears to be a compromised or rogue relay
5. **IP location:** 58.88.x.x range suggests origin from Asia-Pacific region (possibly China)

**Assumption validation:**
- We assume barmail.cs.umass.edu and cs.umass.edu are honest (they're the destination's mail servers)
- The first external IP that contacted barmail is 58.88.21.177 - this is the malicious source
- Everything before barmail.cs.umass.edu in the chain could be forged

---

## P18. DNS and Whois Investigation

### a. What is a whois database?

**Answer:**

A **whois database** is a publicly accessible directory service that provides information about:
- **Domain name registrations:** Owner, registrar, registration/expiration dates
- **IP address allocations:** Organization, contact information, address blocks
- **Autonomous System Numbers (ASN):** Network operators

**Information typically includes:**
- Registrant name and organization
- Administrative and technical contacts
- Registration and expiration dates
- Name servers
- Registrar information
- Contact details (email, phone, address)

**Purpose:**
- Identify domain/IP ownership
- Contact network administrators
- Investigate abuse or security incidents
- Verify domain availability
- Legal and law enforcement investigations

### b. Use whois databases to obtain names of two DNS servers

**Answer:** (Examples - actual results vary)

I'll need to search for information about whois databases and DNS servers.

**Example findings using common whois services:**

**Using ICANN Whois (whois.icann.org):**
- Query: google.com
- DNS Servers: ns1.google.com, ns2.google.com

**Using ARIN Whois (whois.arin.net):**
- Query: mit.edu
- DNS Servers: STRAWB.MIT.EDU, W20NS.MIT.EDU

**Whois databases used:**
1. ICANN Whois (https://whois.icann.org)
2. ARIN Whois (https://whois.arin.net) - North America
3. Regional Internet Registries (RIPE, APNIC, etc.)

### c. Use nslookup to query DNS servers

**Commands:**

```bash
# Query local DNS server
nslookup -type=A google.com
nslookup -type=NS google.com
nslookup -type=MX google.com

# Query specific DNS server (e.g., ns1.google.com)
nslookup -type=A google.com ns1.google.com
nslookup -type=NS google.com ns1.google.com
nslookup -type=MX google.com ns1.google.com

# Query another DNS server (e.g., MIT's)
nslookup -type=A mit.edu STRAWB.MIT.EDU
nslookup -type=NS mit.edu STRAWB.MIT.EDU
nslookup -type=MX mit.edu STRAWB.MIT.EDU
```

**Expected findings:**

**Type A (Address record):**
- Returns IPv4 address(es) of the domain
- Example: google.com → 142.250.185.46

**Type NS (Name Server record):**
- Returns authoritative name servers for the domain
- Example: google.com → ns1.google.com, ns2.google.com, ns3.google.com, ns4.google.com

**Type MX (Mail Exchange record):**
- Returns mail servers for the domain with priority values
- Example: google.com → smtp.google.com (priority 10)

**Summary:** Different DNS servers should return consistent results for authoritative data, though caching may cause temporary discrepancies.

### d. Find a Web server with multiple IP addresses

**Command:**
```bash
nslookup www.google.com
```

**Expected result:**
```
Server: 8.8.8.8
Address: 8.8.8.8#53

Non-authoritative answer:
Name: www.google.com
Address: 142.250.185.36
Name: www.google.com
Address: 2607:f8b0:4004:c07::69
```

**Examples of sites with multiple IPs:**
- **www.google.com** - Multiple IPs for load balancing
- **www.facebook.com** - Multiple IPs globally distributed
- **www.amazon.com** - Many IPs for different regions

**Your institution:** Most universities/companies have multiple IPs for their web servers for:
- Load balancing
- Redundancy/failover
- Geographic distribution
- IPv4 and IPv6 addresses

### e. Determine IP address range using ARIN whois

**Example for a university:**

```bash
whois -h whois.arin.net "University of Massachusetts"
```

**Expected output format:**
```
OrgName: University of Massachusetts
NetRange: 128.119.0.0 - 128.119.255.255
CIDR: 128.119.0.0/16
NetHandle: NET-128-119-0-0-1
Organization: University of Massachusetts
```

**For your institution:**
1. Visit https://whois.arin.net
2. Search for your institution's name
3. Find NetRange or CIDR notation
4. Example ranges:
    - MIT: 18.0.0.0/8
    - Stanford: 171.64.0.0/14

### f. How attackers use whois and nslookup for reconnaissance

**Reconnaissance techniques:**

1. **Domain enumeration:**
    - Find all domains owned by target organization
    - Identify subdomains and related infrastructure

2. **Network mapping:**
    - Discover IP address ranges
    - Identify network topology
    - Find mail servers, DNS servers, web servers

3. **Personnel identification:**
    - Extract contact information
    - Identify administrators (social engineering targets)
    - Find email formats

4. **Infrastructure analysis:**
    - Determine hosting providers
    - Find CDN usage
    - Identify load balancers

5. **Attack surface identification:**
    - Find all public-facing servers
    - Discover forgotten/legacy systems
    - Locate test/development servers

**Attack sequence:**
```
1. whois target.com → Find IP ranges, name servers, contacts
2. nslookup -type=NS target.com → Find authoritative DNS servers
3. nslookup -type=MX target.com → Find mail servers (phishing targets)
4. Zone transfer attempt → Get all DNS records
5. Reverse DNS on IP range → Find all hosts
6. Port scanning identified hosts
7. Vulnerability scanning
8. Exploitation
```

### g. Why whois databases should be publicly available

**Arguments FOR public whois:**

1. **Accountability:**
    - Domain owners can be identified
    - Responsibility for content/actions
    - Prevents anonymous malicious activity

2. **Network operations:**
    - Contact administrators for technical issues
    - Coordinate security incident response
    - Troubleshoot network problems

3. **Legal purposes:**
    - Trademark protection
    - Copyright enforcement
    - Law enforcement investigations

4. **Security:**
    - Report abuse, spam, phishing
    - Track malicious actors
    - Coordinate DDoS mitigation

5. **Transparency:**
    - Public internet resources should have public ownership
    - Promotes trust in internet infrastructure
    - Enables community policing

6. **Business purposes:**
    - Due diligence for partnerships
    - Competitive intelligence (legitimate)
    - Domain acquisition negotiations

**Counterarguments (privacy concerns):**
- Personal information exposure
- Spam/harassment of registrants
- GDPR/privacy regulations
- Solution: Domain privacy services, GDPR-redacted records

**Balance:** Modern whois systems redact personal information while maintaining technical contact methods and organizational transparency.

---

## P19. DNS Hierarchy Exploration with dig

### a. Sequence of queries for department Web server

**Commands and expected delegation chain:**

```bash
# Step 1: Query root server
dig @a.root-servers.net www.cs.university.edu

# Expected response: Referral to .edu TLD servers
# Authority section shows: edu. NS a.edu-servers.net

# Step 2: Query TLD server
dig @a.edu-servers.net www.cs.university.edu

# Expected response: Referral to university.edu name servers
# Authority section shows: university.edu. NS dns1.university.edu

# Step 3: Query university's authoritative server
dig @dns1.university.edu www.cs.university.edu

# Expected response: Final answer with IP address
# Answer section shows: www.cs.university.edu. A 128.119.x.x
```

**Delegation chain example:**
1. **Root server** (a.root-servers.net) → delegates to
2. **TLD server** (a.edu-servers.net) → delegates to
3. **University server** (dns1.university.edu) → delegates to
4. **Department server** (dns.cs.university.edu) → provides final answer

**Example for cs.umass.edu:**
```
Root → .edu TLD → umass.edu → cs.umass.edu
a.root-servers.net → a.edu-servers.net → dns1.umass.edu → ns1.cs.umass.edu
```

### b. Repeat for popular Web sites

**Example 1: google.com**
```bash
dig @a.root-servers.net www.google.com
dig @a.gtld-servers.net www.google.com
dig @ns1.google.com www.google.com
```

**Delegation chain:**
```
Root → .com TLD → google.com
a.root-servers.net → a.gtld-servers.net → ns1.google.com (final answer)
```

**Example 2: yahoo.com**
```bash
dig @a.root-servers.net www.yahoo.com
dig @a.gtld-servers.net www.yahoo.com
dig @ns1.yahoo.com www.yahoo.com
```

**Delegation chain:**
```
Root → .com TLD → yahoo.com
a.root-servers.net → a.gtld-servers.net → ns1.yahoo.com (final answer)
```

**Example 3: amazon.com**
```bash
dig @a.root-servers.net www.amazon.com
dig @a.gtld-servers.net www.amazon.com
dig @pdns1.ultradns.net www.amazon.com
```

**Delegation chain:**
```
Root → .com TLD → amazon.com (uses UltraDNS)
a.root-servers.net → a.gtld-servers.net → pdns1.ultradns.net (final answer)
```

**Common pattern:**
- All start at root servers (13 root server clusters)
- Delegated to appropriate TLD (.com, .org, .edu, etc.)
- Finally to authoritative servers for specific domain
- Typically 3-4 hops from root to final answer

---

## P20. Determine Popular Web Servers from DNS Cache

**Answer:**

**Method:** Analyze cached DNS entries in local DNS server

**Approach:**

1. **Examine cache contents:**
    - Query local DNS server's cache for A records
    - Look for non-local domain names
    - Record frequency and recency of entries

2. **Frequency analysis:**
    - Domains with many cached entries → frequently accessed
    - Recently cached entries → recent access
    - Multiple users accessing same domain → popular site

3. **Indicators of popularity:**
    - **High cache hit rate** for specific domains
    - **Frequent cache refreshes** (TTL expiration and renewal)
    - **Multiple queries** for same domain from different hosts
    - **Long-living cache entries** (frequently accessed before expiration)

**Practical implementation:**

```bash
# If you have access to DNS server logs:
# Count queries for external domains
grep "query" /var/log/named/query.log | \
  grep -v "\.university\.edu" | \
  awk '{print $X}' | sort | uniq -c | sort -rn

# Top domains = most popular sites
```

**Metrics to track:**
- Number of queries per domain
- Number of unique internal IPs querying each domain
- Time distribution of queries
- Cache hit rates

**Example findings:**
```
1523 queries - www.google.com
892 queries - www.youtube.com
634 queries - www.facebook.com
421 queries - github.com
315 queries - stackoverflow.com
```

**Limitations:**
- Doesn't show access via IP (bypassing DNS)
- Doesn't show HTTPS/encrypted content accessed
- Cache may have entries from automated systems
- Short TTLs may underrepresent popular sites

**Privacy consideration:** This method reveals browsing patterns of department users.